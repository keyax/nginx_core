# user  nginx;
worker_processes  1;  # 4 = 2 * Number of CPUs
# worker_processes auto;

#  [ debug | info | notice | warn | error | crit ]
# error_log  /var/log/nginx/error.log warn;
pid        /var/run/nginx.pid;

# daemon off;

events {
    worker_connections  1024;  # 19000 It's the key to high performance - have a lot of connections available
    multi_accept on;

# use [ kqueue | rtsig | epoll | /dev/poll | select | poll ];
#  use kqueue;

}

worker_rlimit_nofile    20000;  # Each connection needs a filehandle (or 2 if you are proxying)
# Total amount of users you can serve = worker_processes * worker_connections

http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

#   log_format  main  '[$time_local] "$request" ($remote_addr - $remote_user) '
    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    access_log  /var/log/nginx/access.log  main;

    sendfile        on;
    #tcp_nopush     on;
    #tcp_nodelay     on;
    keepalive_timeout  65;
    #types_hash_max_size 2048;
    #gzip  on;
    #gzip_disable "msie6";

    #upstream sync_gateway {
    #   server unix:/var/run/php5-fpm.sock;
    #}

    include /etc/nginx/conf.d/*.conf;
#    include /etc/nginx/sites-enabled/*;
}
